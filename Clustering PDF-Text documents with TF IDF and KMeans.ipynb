{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cluster articles by TF IDF and KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I have a number of articles from the site Medium that I have saved to pdf.  This notebook is intended to allow them or any group of articles to be clustered\n",
    "\n",
    "Most of the inputs are the usual suspects with the exception of fitz  Fitz is used because PyPDF2 could not deal with the files.  Fitz is more robust.  \n",
    "Fitz is the name of PyMuPDF. PyMuPDF is a Python binding for MuPDF – “a lightweight PDF and XPS viewer.  `https://github.com/pymupdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "import fitz\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "It is my practice to group functions rather than scatter them across the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_words(alist,features=1000,stops='english',ngram=(1,1)):\n",
    "    vec = TfidfVectorizer(max_df=0.5, max_features=features,\n",
    "                                 min_df=2, stop_words=stops,\n",
    "                                  use_idf=True,\n",
    "                                ngram_range=ngram)\n",
    "    tfidf_matrix = vec.fit_transform(alist).toarray()\n",
    "    df = pd.DataFrame({'Words': vec.get_feature_names(),\n",
    "                       'Summed TFIDF': tfidf_matrix.sum(axis=0)})\n",
    "    sorted_df = df.sort_values('Summed TFIDF', ascending=False)\n",
    "    return sorted_df,tfidf_matrix,vec\n",
    "\n",
    "def count_words(alist):\n",
    "    cv=CountVectorizer(min_df=2, stop_words=stops) \n",
    "    \n",
    "    # this steps generates word counts for the words in your docs \n",
    "    wcv=cv.fit_transform(alist)\n",
    "    return wcv\n",
    "\n",
    "def count_words2(alist,ngram_range=(1,1)):\n",
    "    cv=CountVectorizer(min_df=2, stop_words=stops) \n",
    "    \n",
    "    # this steps generates word counts for the words in your docs \n",
    "    wcv=cv.fit_transform(alist)\n",
    "    return wcv, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This string does 2(1 or 2(0..9),: \\ / ,) to pick up month and day\n",
    "# then  2 or 4 (0..9) to pick up year or am or pm ti pick up time\n",
    "\n",
    "date_time_str = \"^(?:(?:[0-9]{1,2}[:\\/,]){2}[0-9]{2,4}|am|pm)$\"\n",
    "\n",
    "date_str = \"r'[0-9]{1,2}[\\/,:][0-9]{2}[\\/,:][0-9]{2,4}'\"\n",
    "\n",
    "target =\"C:\\\\Working\\\\Medium Articles\"\n",
    "inputs = os.listdir(target)\n",
    "trace = False\n",
    "other_stops = ['https','just','www', 'like','way','used','use','using','http', 'com']\n",
    "stops = set(stopwords.words('english')+ other_stops)\n",
    "\n",
    "nbr_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up blank DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Short_Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Short_Title, Body]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Title','Short_Title','Body']\n",
    "art_df = pd.DataFrame(columns=cols)\n",
    "art_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Short_Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Inventions from Arab Inventors We Were Neve...</td>\n",
       "      <td>10 Inventions from A</td>\n",
       "      <td>[10, Inventions, from, Arab, Inventors, We, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14 Different Types of Learning in Machine Lear...</td>\n",
       "      <td>14 Different Types o</td>\n",
       "      <td>[14, Different, Types, of, Learning, in, Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 Cognitive Bias Key Points Data Scientists Ne...</td>\n",
       "      <td>4 Cognitive Bias Key</td>\n",
       "      <td>[4, Cognitive, Bias, Key, Points, Data, Scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Statistical Traps Data Scientists Should Avoid</td>\n",
       "      <td>5 Statistical Traps</td>\n",
       "      <td>[5, Statistical, Traps, Data, Scientists, Shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Beginners guide to Building your own Face Re...</td>\n",
       "      <td>A Beginners guide to</td>\n",
       "      <td>[A, Beginners, guide, to, Building, your, own,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title           Short_Title  \\\n",
       "0  10 Inventions from Arab Inventors We Were Neve...  10 Inventions from A   \n",
       "1  14 Different Types of Learning in Machine Lear...  14 Different Types o   \n",
       "2  4 Cognitive Bias Key Points Data Scientists Ne...  4 Cognitive Bias Key   \n",
       "3   5 Statistical Traps Data Scientists Should Avoid  5 Statistical Traps    \n",
       "4  A Beginners guide to Building your own Face Re...  A Beginners guide to   \n",
       "\n",
       "                                                Body  \n",
       "0  [10, Inventions, from, Arab, Inventors, We, We...  \n",
       "1  [14, Different, Types, of, Learning, in, Machi...  \n",
       "2  [4, Cognitive, Bias, Key, Points, Data, Scient...  \n",
       "3  [5, Statistical, Traps, Data, Scientists, Shou...  \n",
       "4  [A, Beginners, guide, to, Building, your, own,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    if trace: print(i)\n",
    "    somefo  = 'C:\\\\Working\\\\Medium Articles\\\\'+inputs[i]\n",
    "    doc = fitz.open(somefo) \n",
    "    #print(doc.pageCount)\n",
    "    artstr=\"\"\n",
    "    for j in range(doc.pageCount):\n",
    "        page =doc.loadPage(j)\n",
    "        text = page.getText('text')#.encode(\"utf8\")\n",
    "        textout =str( text).replace(\"\\n\", \" \")\n",
    "        artstr = artstr + textout\n",
    "        #print(textout)\n",
    "        #print(\"****\")\n",
    "    tit =  inputs[i][:-4]\n",
    "    shrt_tit = tit[:20]\n",
    "    artlist = artstr.split()\n",
    "    new_list = [item for item in artlist if not re.search(r'[0-9]{1,2}[\\/,:][0-9]{2}[\\/,:][0-9]{2,4}', item)]\n",
    "    art_df.loc[i] = [tit,shrt_tit, new_list]\n",
    "   \n",
    "        \n",
    "art_df.head ()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short examination of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of word counts, articles, unique words (188, 9821)\n"
     ]
    }
   ],
   "source": [
    "words_in_articles = []\n",
    "words_in_doc = []\n",
    "# Glom into a list of strings\n",
    "for i  in range(len(art_df)):\n",
    "    words_in_articles.append(\" \".join(art_df.iloc[i].Body) ) \n",
    "\n",
    "word_count,vec = count_words2( words_in_articles)\n",
    "print(\"The shape of word counts, articles, unique words\",word_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>3603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "data      3603\n",
       "learning  3445\n",
       "model     2418\n",
       "100       2197\n",
       "machine   1559\n",
       "image     1467\n",
       "python    1454\n",
       "one       1343\n",
       "science   1216\n",
       "medium    1135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_df = pd.DataFrame(word_count.sum(axis=0),\n",
    "             columns=vec.get_feature_names()).T.sort_values(0,ascending=False)\n",
    "sort_df.head(10)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document clustering with TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Summed TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>face</td>\n",
       "      <td>10.707552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>detection</td>\n",
       "      <td>7.838385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>recognition</td>\n",
       "      <td>7.658588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>towardsdatascience</td>\n",
       "      <td>7.506433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>images</td>\n",
       "      <td>5.519965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>network</td>\n",
       "      <td>5.069635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>object</td>\n",
       "      <td>4.709820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>seaborn</td>\n",
       "      <td>4.566327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>kdnuggets</td>\n",
       "      <td>4.493308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>keras</td>\n",
       "      <td>4.441106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>neural</td>\n",
       "      <td>4.400548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>audio</td>\n",
       "      <td>4.206238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>import</td>\n",
       "      <td>3.912334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>plot</td>\n",
       "      <td>3.776481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>github</td>\n",
       "      <td>3.693067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>life</td>\n",
       "      <td>3.689747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>optimization</td>\n",
       "      <td>3.584027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>guide</td>\n",
       "      <td>3.576938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>3.570153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>classification</td>\n",
       "      <td>3.552093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Words  Summed TFIDF\n",
       "329                face     10.707552\n",
       "262           detection      7.838385\n",
       "729         recognition      7.658588\n",
       "912  towardsdatascience      7.506433\n",
       "443              images      5.519965\n",
       "580             network      5.069635\n",
       "601              object      4.709820\n",
       "788             seaborn      4.566327\n",
       "486           kdnuggets      4.493308\n",
       "487               keras      4.441106\n",
       "582              neural      4.400548\n",
       "105               audio      4.206238\n",
       "450              import      3.912334\n",
       "662                plot      3.776481\n",
       "391              github      3.693067\n",
       "511                life      3.689747\n",
       "611        optimization      3.584027\n",
       "411               guide      3.576938\n",
       "993             xgboost      3.570153\n",
       "170      classification      3.552093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_df,tf_matrix,vec = rank_words(words_in_articles)\n",
    "sort_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TF IDF Matrix is articles by words, defaults to 1000  (188, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\"The TF IDF Matrix is articles by words, defaults to 1000 \",tf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance is 1 - cosine similarity\n",
    "\n",
    "this will have the dimensions articles by articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Short_Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Inventions from Arab Inventors We Were Neve...</td>\n",
       "      <td>10 Inventions from A</td>\n",
       "      <td>[10, Inventions, from, Arab, Inventors, We, We...</td>\n",
       "      <td>[-2.220446049250313e-16, 0.974749517654662, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14 Different Types of Learning in Machine Lear...</td>\n",
       "      <td>14 Different Types o</td>\n",
       "      <td>[14, Different, Types, of, Learning, in, Machi...</td>\n",
       "      <td>[0.974749517654662, -4.440892098500626e-16, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 Cognitive Bias Key Points Data Scientists Ne...</td>\n",
       "      <td>4 Cognitive Bias Key</td>\n",
       "      <td>[4, Cognitive, Bias, Key, Points, Data, Scient...</td>\n",
       "      <td>[0.9851655938314126, 0.9298484722934943, -2.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Statistical Traps Data Scientists Should Avoid</td>\n",
       "      <td>5 Statistical Traps</td>\n",
       "      <td>[5, Statistical, Traps, Data, Scientists, Shou...</td>\n",
       "      <td>[0.9750108243336555, 0.8915423404430383, 0.547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Beginners guide to Building your own Face Re...</td>\n",
       "      <td>A Beginners guide to</td>\n",
       "      <td>[A, Beginners, guide, to, Building, your, own,...</td>\n",
       "      <td>[0.9854114570245276, 0.9617390194930834, 0.947...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title           Short_Title  \\\n",
       "0  10 Inventions from Arab Inventors We Were Neve...  10 Inventions from A   \n",
       "1  14 Different Types of Learning in Machine Lear...  14 Different Types o   \n",
       "2  4 Cognitive Bias Key Points Data Scientists Ne...  4 Cognitive Bias Key   \n",
       "3   5 Statistical Traps Data Scientists Should Avoid  5 Statistical Traps    \n",
       "4  A Beginners guide to Building your own Face Re...  A Beginners guide to   \n",
       "\n",
       "                                                Body  \\\n",
       "0  [10, Inventions, from, Arab, Inventors, We, We...   \n",
       "1  [14, Different, Types, of, Learning, in, Machi...   \n",
       "2  [4, Cognitive, Bias, Key, Points, Data, Scient...   \n",
       "3  [5, Statistical, Traps, Data, Scientists, Shou...   \n",
       "4  [A, Beginners, guide, to, Building, your, own,...   \n",
       "\n",
       "                                                Dist  \n",
       "0  [-2.220446049250313e-16, 0.974749517654662, 0....  \n",
       "1  [0.974749517654662, -4.440892098500626e-16, 0....  \n",
       "2  [0.9851655938314126, 0.9298484722934943, -2.22...  \n",
       "3  [0.9750108243336555, 0.8915423404430383, 0.547...  \n",
       "4  [0.9854114570245276, 0.9617390194930834, 0.947...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_df['Dist'] =\"\"\n",
    "for i in range(len(art_df)):\n",
    "    art_df.Dist.iloc[i] = dist[i]\n",
    "\n",
    "art_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the articles based on the TF IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
       "                init_size=1000, max_iter=100, max_no_improvement=10,\n",
       "                n_clusters=20, n_init=1, random_state=None,\n",
       "                reassignment_ratio=0.01, tol=0.0, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = MiniBatchKMeans(n_clusters=20,\n",
    "                    init='k-means++', n_init=1,\n",
    "                    init_size=1000,\n",
    "                    batch_size=1000 )\n",
    "\n",
    "km.fit(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      " object yolo detection vision visionwizard computer network boxes dive keras\n",
      "\n",
      "Cluster 1\n",
      " reinforcement meta agent game policy reward state action actions planning\n",
      "\n",
      "Cluster 2\n",
      " recognition facial detection object images projects 2020 towardsdatascience kdnuggets news\n",
      "\n",
      "Cluster 3\n",
      " jupyter notebook colab windows notebooks transfer towardsdatascience task text gpu\n",
      "\n",
      "Cluster 4\n",
      " optimization bayesian hyperparameter hyperopt xgboost acquisition search tuning hyperparameters optimize\n",
      "\n",
      "Cluster 5\n",
      " seaborn visualization plot nerds neuralnets shall plots color random sns\n",
      "\n",
      "Cluster 6\n",
      " face recognition faces detection images opencv celebrity facial keras cv2\n",
      "\n",
      "Cluster 7\n",
      " life people schwartz things years day think utm_campaign utm_source book\n",
      "\n",
      "Cluster 8\n",
      " kdnuggets cognitive bias html biases detection www distribution clustering sne\n",
      "\n",
      "Cluster 9\n",
      " xgboost towardsdatascience sne feature variable false regression web hyper catboost\n",
      "\n",
      "Cluster 10\n",
      " tensorflow tf cnn convolutional neural label multi classification kl network\n",
      "\n",
      "Cluster 11\n",
      " speech analyticsvidhya kdnuggets transfer inception www text keras coding easy\n",
      "\n",
      "Cluster 12\n",
      " gpt transformer attention self word decoder visualizing sequence illustrated jalammar\n",
      "\n",
      "Cluster 13\n",
      " bert weed robots knowledge human robot understanding language humans company\n",
      "\n",
      "Cluster 14\n",
      " git github branch repository changes developers pull commit project guide\n",
      "\n",
      "Cluster 15\n",
      " voice stft pandas speech dataframe file map signal format frequency\n",
      "\n",
      "Cluster 16\n",
      " detection object caption keras images opencv os self cv2 merge\n",
      "\n",
      "Cluster 17\n",
      " cube paradise white piece solve layer left edge center algorithm\n",
      "\n",
      "Cluster 18\n",
      " audio sound heart event classification challenge noise processing file 2016\n",
      "\n",
      "Cluster 19\n",
      " hominin al scholar homo fossil africa species author university genus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms = vec.get_feature_names()\n",
    "for i in range(km.cluster_centers_.shape[0]):\n",
    "    print(\"Cluster \"+ str(i))\n",
    "    for j in order_centroids[i,:10]:\n",
    "        print(' %s' % terms[j], end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the clusters to the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Short_Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Dist</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Simple Guide to Using Keras Pretrained Model...</td>\n",
       "      <td>A Simple Guide to Us</td>\n",
       "      <td>[A, Simple, Guide, to, Using, Keras, Pretraine...</td>\n",
       "      <td>[0.9951149769326811, 0.9485160814292422, 0.977...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Computer Vision for Automatic Road Damage Dete...</td>\n",
       "      <td>Computer Vision for</td>\n",
       "      <td>[Computer, Vision, for, Automatic, Road, Damag...</td>\n",
       "      <td>[0.9609625329766408, 0.9401862216903285, 0.989...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DETR _ Object Detection _ Facebook AI _ Vision...</td>\n",
       "      <td>DETR _ Object Detect</td>\n",
       "      <td>[DETR, |, Object, Detection, |, Facebook, AI, ...</td>\n",
       "      <td>[0.9689487017940672, 0.9157330173729323, 0.977...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Deep Dive into the Computer Vision World_ Part...</td>\n",
       "      <td>Deep Dive into the C</td>\n",
       "      <td>[Deep, Dive, into, the, Computer, Vision, Worl...</td>\n",
       "      <td>[0.9502165337103473, 0.9240473090544705, 0.973...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Deep Dive into the Computer Vision World_ Part...</td>\n",
       "      <td>Deep Dive into the C</td>\n",
       "      <td>[Deep, Dive, into, the, Computer, Vision, Worl...</td>\n",
       "      <td>[0.941781243737909, 0.9259461616419888, 0.9697...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Sound Event Classification_ A to Z _ by Chathu...</td>\n",
       "      <td>Sound Event Classifi</td>\n",
       "      <td>[Sound, Event, Classification:, A, to, Z, |, b...</td>\n",
       "      <td>[0.988232849639684, 0.9760101112847869, 0.9936...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Inventions from Arab Inventors We Were Neve...</td>\n",
       "      <td>10 Inventions from A</td>\n",
       "      <td>[10, Inventions, from, Arab, Inventors, We, We...</td>\n",
       "      <td>[-2.220446049250313e-16, 0.974749517654662, 0....</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Earliest hominin migrations into the Arabian P...</td>\n",
       "      <td>Earliest hominin mig</td>\n",
       "      <td>[Earliest, hominin, migrations, into, the, Ara...</td>\n",
       "      <td>[0.8645867475945946, 0.9524164560443134, 0.963...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Origin of the Genus Homo _ SpringerLink</td>\n",
       "      <td>Origin of the Genus</td>\n",
       "      <td>[Origin, of, the, Genus, Homo, |, SpringerLink...</td>\n",
       "      <td>[0.8796275220851925, 0.9820810317990794, 0.987...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>The hominin fossil record_ taxa, grades and cl...</td>\n",
       "      <td>The hominin fossil r</td>\n",
       "      <td>[The, hominin, fossil, record:, taxa,, grades,...</td>\n",
       "      <td>[0.8784240765272334, 0.9626945380376947, 0.982...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title           Short_Title  \\\n",
       "11   A Simple Guide to Using Keras Pretrained Model...  A Simple Guide to Us   \n",
       "32   Computer Vision for Automatic Road Damage Dete...  Computer Vision for    \n",
       "50   DETR _ Object Detection _ Facebook AI _ Vision...  DETR _ Object Detect   \n",
       "42   Deep Dive into the Computer Vision World_ Part...  Deep Dive into the C   \n",
       "43   Deep Dive into the Computer Vision World_ Part...  Deep Dive into the C   \n",
       "..                                                 ...                   ...   \n",
       "149  Sound Event Classification_ A to Z _ by Chathu...  Sound Event Classifi   \n",
       "0    10 Inventions from Arab Inventors We Were Neve...  10 Inventions from A   \n",
       "58   Earliest hominin migrations into the Arabian P...  Earliest hominin mig   \n",
       "132            Origin of the Genus Homo _ SpringerLink  Origin of the Genus    \n",
       "157  The hominin fossil record_ taxa, grades and cl...  The hominin fossil r   \n",
       "\n",
       "                                                  Body  \\\n",
       "11   [A, Simple, Guide, to, Using, Keras, Pretraine...   \n",
       "32   [Computer, Vision, for, Automatic, Road, Damag...   \n",
       "50   [DETR, |, Object, Detection, |, Facebook, AI, ...   \n",
       "42   [Deep, Dive, into, the, Computer, Vision, Worl...   \n",
       "43   [Deep, Dive, into, the, Computer, Vision, Worl...   \n",
       "..                                                 ...   \n",
       "149  [Sound, Event, Classification:, A, to, Z, |, b...   \n",
       "0    [10, Inventions, from, Arab, Inventors, We, We...   \n",
       "58   [Earliest, hominin, migrations, into, the, Ara...   \n",
       "132  [Origin, of, the, Genus, Homo, |, SpringerLink...   \n",
       "157  [The, hominin, fossil, record:, taxa,, grades,...   \n",
       "\n",
       "                                                  Dist  Cluster  \n",
       "11   [0.9951149769326811, 0.9485160814292422, 0.977...        0  \n",
       "32   [0.9609625329766408, 0.9401862216903285, 0.989...        0  \n",
       "50   [0.9689487017940672, 0.9157330173729323, 0.977...        0  \n",
       "42   [0.9502165337103473, 0.9240473090544705, 0.973...        0  \n",
       "43   [0.941781243737909, 0.9259461616419888, 0.9697...        0  \n",
       "..                                                 ...      ...  \n",
       "149  [0.988232849639684, 0.9760101112847869, 0.9936...       18  \n",
       "0    [-2.220446049250313e-16, 0.974749517654662, 0....       19  \n",
       "58   [0.8645867475945946, 0.9524164560443134, 0.963...       19  \n",
       "132  [0.8796275220851925, 0.9820810317990794, 0.987...       19  \n",
       "157  [0.8784240765272334, 0.9626945380376947, 0.982...       19  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = km.labels_.tolist()\n",
    "art_df['Cluster'] = clusters\n",
    "\n",
    "art_df.sort_values(['Cluster', 'Short_Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
